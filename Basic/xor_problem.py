# -*- coding: utf-8 -*-
"""XOR problem

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Oe_seAnOj5uPMfzdkeZmIuvboeEkLkNz

## XOR

The best way to learn is to code it yourself. Try building a nerual network to solve the XOR problem below. Can it be solved by a network with no hidden layers?

*Hint: for a binary classification loss function consider checking out `torch.nn.BCEWithLogitsLoss`*
"""

import numpy as np
import matplotlib.pyplot as plt
import torch

X = np.random.uniform(-1, 1, size=(4000, 2))
X

y = ((X[:, 0] >= 0) ^ (X[:, 1] >= 0)).astype(int)
y

plt.figure(figsize=(3, 3), dpi=100)
plt.scatter(*X.T, c=y,cmap='PiYG', s=5)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(device)

from tqdm import trange
from torch import nn
import torch.nn.functional as F

model = nn.Sequential(
    nn.Linear(2, 4000),
    nn.ReLU(),
    nn.Linear(4000, 1)
).to(device)

# Optimization with BGD method

opt = torch.optim.Adam(model.parameters(), lr=1e-4)
num_epoch = 15
batch_size = 128

loss_fn = torch.nn.BCEWithLogitsLoss()

for epoch in range(num_epoch):
  shuffle_ids = np.random.permutation(len(X))
  for idx in trange(0, len(X), batch_size):
    batch_X = torch.tensor(X[shuffle_ids][idx : idx + batch_size], dtype=torch.float32).to(device)
    batch_y = torch.tensor(y[shuffle_ids][idx : idx + batch_size], dtype=torch.float32).unsqueeze(1).to(device)

    loss = loss_fn(model(batch_X), batch_y)
    loss.backward()
    opt.step()
    opt.zero_grad()

prediction = model(
    torch.tensor(X, dtype=torch.float32).to(device)
).cpu().detach().numpy().squeeze()

accuracy = ((prediction > 0.).astype(int) == y).mean()
accuracy

